{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import imblearn\n",
    "import matplotlib\n",
    "import os\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def print_environment_info():\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"Python Version:\", sys.version)\n",
    "    print(\"Python Executable:\", sys.executable)\n",
    "    print(\"Operating System:\", platform.system(), platform.release())\n",
    "    print(\"Platform:\", platform.platform())\n",
    "    print(\"Architecture:\", platform.architecture())\n",
    "    print(\"NumPy Version:\", np.__version__)\n",
    "    print(\"Pandas Version:\", pd.__version__)\n",
    "    print(\"TensorFlow Version:\", tf.__version__)\n",
    "    print(\"imblearn Version:\", imblearn.__version__)\n",
    "    print(\"Matplotlib Version:\", matplotlib.__version__)\n",
    "    print(\"Current Working Directory:\", os.getcwd())\n",
    "    print(\"Installed Packages:\")\n",
    "    os.system(\"pip freeze\")\n",
    "\n",
    "    print(\"\\nHardware Information:\")\n",
    "    try:\n",
    "        if platform.system() == \"Windows\":\n",
    "            subprocess.call(['wmic', 'csproduct', 'get', 'name'])\n",
    "            subprocess.call(['wmic', 'cpu', 'get', 'name'])\n",
    "        elif platform.system() == \"Linux\":\n",
    "            subprocess.call(['cat', '/proc/cpuinfo'])\n",
    "            subprocess.call(['lscpu'])\n",
    "        elif platform.system() == \"Darwin\":\n",
    "            subprocess.call(['sysctl', 'hw'])\n",
    "    except Exception as e:\n",
    "        print(\"Could not retrieve hardware information:\", e)\n",
    "\n",
    "    print(\"\\nSoftware Versions:\")\n",
    "    packages = ['scikit-learn', 'scipy', 'Pillow', 'jupyter', 'seaborn',\n",
    "        'keras','matplotlib','numpy','tensorflow','imblearn','statsmodels',\n",
    "        'xgboost','lightgbm','catboost','optuna','tensorflow_addons','joblib',\n",
    "        'tqdm']\n",
    "\n",
    "    for package in packages:\n",
    "        try:\n",
    "            version = pkg_resources.get_distribution(package).version\n",
    "            print(f\"{package} Version: {version}\")\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            print(f\"{package} is not installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class OptoelectronicDataGenerator:\n",
    "    def __init__(self, n_samples, I_s=0.5):\n",
    "        self.n_samples = n_samples\n",
    "        self.I_s = I_s\n",
    "        self.material_properties = {\n",
    "            0: {'name': 'Silicon (Si)', 'coefficient': 1.0},\n",
    "            1: {'name': 'Gallium Arsenide (GaAs)', 'coefficient': 0.9},\n",
    "            2: {'name': 'Indium Phosphide (InP)', 'coefficient': 1.1},\n",
    "            3: {'name': 'Germanium (Ge)', 'coefficient': 0.95},\n",
    "            4: {'name': 'Zinc Oxide (ZnO)', 'coefficient': 1.2}\n",
    "        }\n",
    "\n",
    "    def generate_data(self, random_seed=72):\n",
    "        light_intensity = np.random.rand(self.n_samples) * 800_000  # Light intensity: 0 to 800,000 Lux\n",
    "        temperature = np.random.rand(self.n_samples) * 100 - 20  # Temperature: -20°C to 80°C\n",
    "        material_types = np.random.randint(0, 5, self.n_samples)  # Five different materials (0-4)\n",
    "        humidity = np.random.rand(self.n_samples) * 100  # Humidity: 0% to 100%\n",
    "        wavelength = np.random.rand(self.n_samples) * 300 + 400  # Wavelength: 400 nm to 700 nm\n",
    "        pressure = np.random.rand(self.n_samples) * 200 + 900  # Pressure: 900 hPa to 1100 hPa\n",
    "        thickness = np.random.rand(self.n_samples) * 10  # Thickness: 0 to 10 µm\n",
    "        impurity = np.random.rand(self.n_samples) * 0.02  # Impurity concentration: 0 to 2%\n",
    "        bias = np.random.rand(self.n_samples) * 10 - 5  # Bias: -5V to 5V\n",
    "        surface = np.random.randint(0, 2, self.n_samples)  # Surface treatment: 0 (none) or 1 (treated)\n",
    "        electric_field = np.random.rand(self.n_samples) * 1000  # Electric field strength: 0 to 1000 V/m\n",
    "        density = np.random.rand(self.n_samples) * 10 + 1  # Material density: 1 to 11 g/cm³\n",
    "\n",
    "        X = np.column_stack((light_intensity, temperature, material_types, humidity,\n",
    "                             wavelength, pressure, thickness, impurity, bias,\n",
    "                             surface, electric_field, density))\n",
    "        \n",
    "        y = self._calculate_current(X, material_types)\n",
    "        return X, y\n",
    "\n",
    "    def _calculate_current(self, X, material_types, random_seed=72):\n",
    "        n = self.n_samples\n",
    "        noise = np.random.normal(0, 0.1, n)  # Add noise\n",
    "        current = np.zeros(n)\n",
    "        \n",
    "        for i in range(n):\n",
    "            current[i] = (X[i, 0] * self.material_properties[material_types[i]]['coefficient'] +\n",
    "                          X[i, 1] * 0.5 + \n",
    "                          X[i, 3] * 0.05 +\n",
    "                          X[i, 4] * 0.002 + \n",
    "                          X[i, 5] * 0.001 +\n",
    "                          X[i, 6] * 0.03 + \n",
    "                          X[i, 7] * 0.1 +\n",
    "                          X[i, 8] * 0.2 + \n",
    "                          X[i, 9] * 0.3 +\n",
    "                          X[i, 10] * 0.01 +  \n",
    "                          X[i, 11] * 0.1 +           \n",
    "                          self.I_s) + noise[i]\n",
    "        \n",
    "        return current\n",
    "\n",
    "    def preprocess_data(self, random_seed=72):\n",
    "        X, y = self.generate_data()\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Split into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_val, y_train, y_val, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Adagrad, Adamax, Nadam, Ftrl\n",
    "\n",
    "# Ensure the checkpoint directory exists\n",
    "checkpoint_dir = './checkpoint/'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "def train_and_evaluate_models(model_function, X_train, y_train, X_val, y_val, optimizer, random_seed=0):\n",
    "    # Create and compile the feedforward model\n",
    "    model, catboost = model_function(X_train.shape[1])\n",
    "    \n",
    "    # Define checkpoint filepath here\n",
    "    checkpoint_filepath = f'./checkpoint/{model_function.__name__}_{optimizer.__class__.__name__}_best_model.h5'\n",
    "        \n",
    "    # Set callback functions\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_filepath, \n",
    "                                        monitor='val_loss', \n",
    "                                        save_best_only=True, \n",
    "                                        mode='min', \n",
    "                                        verbose=0)\n",
    "    # Compile model with the given optimizer\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Train the feedforward model\n",
    "    history_first = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                              epochs=60, batch_size=32, callbacks=[early_stopping, reduce_lr, model_checkpoint], \n",
    "                              verbose=0)\n",
    "\n",
    "    # Get the best epoch and corresponding validation loss from the first round\n",
    "    best_epoch_first = np.argmin(history_first.history['val_loss']) + 1\n",
    "    best_val_loss_first = min(history_first.history['val_loss'])\n",
    "    \n",
    "    # Train the feedforward model for the second time\n",
    "    history_second = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                               epochs=30, batch_size=32, callbacks=[early_stopping, reduce_lr, model_checkpoint], \n",
    "                               verbose=0)\n",
    "\n",
    "    # Get the best epoch and corresponding validation loss from the second round\n",
    "    best_epoch_second = np.argmin(history_second.history['val_loss']) + 1\n",
    "    best_val_loss_second = min(history_second.history['val_loss'])\n",
    "    \n",
    "    # Evaluate neural network\n",
    "    y_pred_nn = model.predict(X_val)\n",
    "    mse_nn = mean_squared_error(y_val, y_pred_nn)\n",
    "    mae_nn = mean_absolute_error(y_val, y_pred_nn)\n",
    "    r2_nn = r2_score(y_val, y_pred_nn)\n",
    "    rmse_nn = np.sqrt(mse_nn)\n",
    "\n",
    "    # Print neural network metrics\n",
    "    print(f'\\nNeural Network Metrics (ANN):')\n",
    "    print(f'Root Mean Square Error: {rmse_nn:.6f}')\n",
    "    print(f'Mean Squared Error: {mse_nn:.6f}')\n",
    "    print(f'Mean Absolute Error: {mae_nn:.6f}')\n",
    "    print(f'R² Score: {r2_nn:.6f}')\n",
    "\n",
    "    # Use EcoCurrentNet的输出数据作为新的目标变量\n",
    "    y_train_nn = model.predict(X_train)  # Changed this to use the model instead of feedforward_model\n",
    "    \n",
    "    # Fit the CatBoost model\n",
    "    catboost.fit(X_train, y_train_nn)\n",
    "\n",
    "    # Make predictions and evaluate\n",
    "    y_pred_catboost = catboost.predict(X_val)  # Changed this to use catboost instead of catboost_model\n",
    "    r2_catboost = r2_score(y_val, y_pred_catboost)\n",
    "\n",
    "    # Calculate additional metrics for CatBoost\n",
    "    mse_catboost = mean_squared_error(y_val, y_pred_catboost)\n",
    "    mae_catboost = mean_absolute_error(y_val, y_pred_catboost)\n",
    "    rmse_catboost = np.sqrt(mse_catboost)\n",
    "\n",
    "    # Print metrics for CatBoost model\n",
    "    print(f'\\nCatBoost Metrics (CatBoost):')\n",
    "    print(f'Root Mean Square Error: {rmse_catboost:.6f}')\n",
    "    print(f'Mean Squared Error: {mse_catboost:.6f}')\n",
    "    print(f'Mean Absolute Error: {mae_catboost:.6f}')\n",
    "    print(f'R² Score: {r2_catboost:.6f}')\n",
    "    print('----------')\n",
    "    print(f'Best Epoch (First Round): {best_epoch_first}, Validation Loss: {best_val_loss_first:.6f}')\n",
    "    print(f'Best Epoch (Second Round): {best_epoch_second}, Validation Loss: {best_val_loss_second:.6f}\\n')\n",
    "        \n",
    "    # Save metrics to checkpoint\n",
    "    metrics = {\n",
    "        'Model Name': model_function.__name__,\n",
    "        'Optimizer': optimizer.__class__.__name__,\n",
    "        'RMSE': rmse_catboost,\n",
    "        'MSE': mse_catboost,\n",
    "        'MAE': mae_catboost,\n",
    "        'R²': r2_catboost\n",
    "    }\n",
    "    \n",
    "    # Save metrics to a DataFrame\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    metrics_file_path = os.path.join(checkpoint_dir, 'model_metrics.xlsx')\n",
    "\n",
    "    # Append the metrics to the Excel file\n",
    "    if os.path.exists(metrics_file_path):\n",
    "        metrics_df.to_excel(metrics_file_path, index=False, header=False, startrow=len(pd.read_excel(metrics_file_path)) + 1)\n",
    "    else:\n",
    "        metrics_df.to_excel(metrics_file_path, index=False)\n",
    "    \n",
    "    # Return metrics for further analysis\n",
    "    return rmse_nn, mse_nn, mae_nn, r2_nn, rmse_catboost, mse_catboost, mae_catboost, r2_catboost, (best_epoch_first, best_val_loss_first), (best_epoch_second, best_val_loss_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_and_optimizers(X_train, y_train, X_val, y_val):\n",
    "    optimizers = [\n",
    "        ('Adam', Adam(learning_rate=0.001)),\n",
    "        ('RMSprop', RMSprop(learning_rate=0.001)),\n",
    "        ('Adagrad', Adagrad(learning_rate=0.001)),\n",
    "        ('Adamax', Adamax(learning_rate=0.001)),\n",
    "        ('Nadam', Nadam(learning_rate=0.001)),\n",
    "        ('Ftrl', Ftrl(learning_rate=0.001))\n",
    "    ]\n",
    "\n",
    "    model_functions = [\n",
    "        EcoCurrentNet_V1, EcoCurrentNet_V2, EcoCurrentNet_V3,\n",
    "        EcoCurrentNet_V4, EcoCurrentNet_V5\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_function in model_functions:\n",
    "        print('\\n------------------------------------------------------')\n",
    "        print(f\"Evaluating model: {model_function.__name__}\")\n",
    "        \n",
    "        for opt_name, optimizer in optimizers:\n",
    "            print(f\"  Evaluating with optimizer: {opt_name}\")\n",
    "            metrics = train_and_evaluate_models(model_function, X_train, y_train, X_val, y_val, optimizer)\n",
    "            if metrics is not None:\n",
    "                results[(model_function.__name__, opt_name)] = metrics\n",
    "\n",
    "    # Print results sorted by r2_catboost in descending order\n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    print(f'{\"Model Name\":<30} {\"Optimizer\":<15} {\"R² Score (CatBoost)\":<10}')\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Sort results by r2_catboost and print\n",
    "    sorted_results = sorted(results.items(), key=lambda item: item[1][3], reverse=True)\n",
    "    for (model_name, opt_name), metrics in sorted_results[:]:\n",
    "        print(f\"{model_name} - {opt_name}: r2_catboost = {metrics[3]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling1D, Add, Input\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Model\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "class CatBoostLayer(Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CatBoostLayer, self).__init__(**kwargs)\n",
    "        self.catboost = CatBoostRegressor(silent=True)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.catboost.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.catboost.predict(X)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.predict(inputs)\n",
    "\n",
    "def residual_block(x, filters):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Conv1D(filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    return x\n",
    "\n",
    "def EcoCurrentNet(input_shape, num_classes=5):\n",
    "    model_inputs = Input(shape=(input_shape, 1))\n",
    "    x = Conv1D(64, kernel_size=3, padding='same')(model_inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    # 添加残差块\n",
    "    x = residual_block(x, 64)\n",
    "\n",
    "    # 第二层卷积\n",
    "    x = Conv1D(128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    # 添加残差块\n",
    "    x = residual_block(x, 128)\n",
    "\n",
    "    # 第三层卷积\n",
    "    x = Conv1D(256, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # 全局平均池化层\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # 全连接层\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # 输出层\n",
    "    outputs = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=model_inputs, outputs=outputs)\n",
    "    catboost = CatBoostLayer()\n",
    "    \n",
    "    return model, catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "def train(EcoCurrentNet, X_train, y_train, X_val, y_val, random_seed=0):\n",
    "    # Create and compile the feedforward model\n",
    "    model, catboost = EcoCurrentNet(X_train.shape[1])\n",
    "    \n",
    "    # Define checkpoint filepath here\n",
    "    checkpoint = './checkpoint/EcoCurrentNet_best_model.h5'\n",
    "        \n",
    "    # Set callback functions\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint, \n",
    "                                        monitor='val_loss', \n",
    "                                        save_best_only=True, \n",
    "                                        mode='min', \n",
    "                                        verbose=0)\n",
    "\n",
    "    # Compile model with RMSprop optimizer\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "    # Train the feedforward model\n",
    "    history_first = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                              epochs=60, batch_size=32, callbacks=[early_stopping, model_checkpoint], \n",
    "                              verbose=0)\n",
    "\n",
    "    # Get the best epoch and corresponding validation loss from the first round\n",
    "    best_epoch_first = np.argmin(history_first.history['val_loss']) + 1\n",
    "    best_val_loss_first = min(history_first.history['val_loss'])\n",
    "    \n",
    "    # Train the feedforward model for the second time\n",
    "    history_second = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                               epochs=30, batch_size=32, callbacks=[early_stopping, reduce_lr, model_checkpoint], \n",
    "                               verbose=0)\n",
    "\n",
    "    # Get the best epoch and corresponding validation loss from the second round\n",
    "    best_epoch_second = np.argmin(history_second.history['val_loss']) + 1\n",
    "    best_val_loss_second = min(history_second.history['val_loss'])\n",
    "\n",
    "    # Use EcoCurrentNet的输出数据作为新的目标变量\n",
    "    y_train_nn = model.predict(X_train)  # Changed this to use the model instead of feedforward_model\n",
    "    \n",
    "    # Fit the CatBoost model\n",
    "    catboost.fit(X_train, y_train_nn)\n",
    "\n",
    "    # Make predictions and evaluate\n",
    "    y_pred_catboost = catboost.predict(X_val)  # Changed this to use catboost instead of catboost_model\n",
    "    r2 = r2_score(y_val, y_pred_catboost)\n",
    "\n",
    "    # Calculate additional metrics for CatBoost\n",
    "    mse = mean_squared_error(y_val, y_pred_catboost)\n",
    "    mae = mean_absolute_error(y_val, y_pred_catboost)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Print metrics for CatBoost model\n",
    "    print(f'\\nCatBoost Metrics (CatBoost):')\n",
    "    print(f'Root Mean Square Error: {rmse:.6f}')\n",
    "    print(f'Mean Squared Error: {mse:.6f}')\n",
    "    print(f'Mean Absolute Error: {mae:.6f}')\n",
    "    print(f'R² Score: {r2:.6f}')\n",
    "    print('----------\\n')\n",
    "    \n",
    "    # Save metrics to checkpoint\n",
    "    metrics = {\n",
    "        'RMSE': rmse,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'R²': r2\n",
    "    }\n",
    "    \n",
    "    # Save metrics to a DataFrame\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    metrics_file_path = os.path.join('./EcoCurrentNet_metrics.xlsx')\n",
    "    \n",
    "    # Plot history\n",
    "    plot_loss(history_first, title='Training and Validation Loss (First Phase)')\n",
    "    plot_loss(history_second, title='Training and Validation Loss (Second Phase)')\n",
    "\n",
    "    # Call the function to plot True vs. Predicted values after model evaluation\n",
    "    plot_true_vs_predicted(y_val, y_pred_catboost, title='True vs. Predicted Values for Model Evaluation')\n",
    "\n",
    "    # Call the function to plot residuals after model evaluation\n",
    "    plot_residuals(y_val, y_pred_catboost, title='Residuals of Predictions for Model Evaluation')\n",
    "\n",
    "    # Return metrics for further analysis\n",
    "    return rmse, mse, mae, r2, (best_epoch_first, best_val_loss_first), (best_epoch_second, best_val_loss_second), y_pred_catboost, X_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_material_properties_before_training(X, y, material_properties):\n",
    "    # 提取特征\n",
    "    material_types = X[:, 2].astype(int)\n",
    "    light_intensity = X[:, 0]\n",
    "    temperature = X[:, 1]\n",
    "    humidity = X[:, 3]\n",
    "    wavelength = X[:, 4]\n",
    "    pressure = X[:, 5]\n",
    "    thickness = X[:, 6]\n",
    "    impurity = X[:, 7]\n",
    "    bias = X[:, 8]\n",
    "    electric_field = X[:, 9]\n",
    "    density = X[:, 10]\n",
    "    surface = X[:, 11]\n",
    "    \n",
    "    # 定义颜色和标签\n",
    "    colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "    material_labels = [material_properties[i]['name'] for i in range(5)]\n",
    "\n",
    "    plt.figure(figsize=(30, 20))\n",
    "\n",
    "    # 特征与数据的对应列表\n",
    "    features = [\n",
    "        (light_intensity, 'Light Intensity (Lux)'),\n",
    "        (temperature, 'Temperature (°C)'),\n",
    "        (humidity, 'Humidity (%)'),\n",
    "        (wavelength, 'Wavelength (nm)'),\n",
    "        (pressure, 'Pressure (hPa)'),\n",
    "        (thickness, 'Thickness (µm)'),\n",
    "        (impurity, 'Impurity Concentration (%)'),\n",
    "        (bias, 'Bias (V)'),\n",
    "        (electric_field, 'Electric Field (V/m)'),\n",
    "        (density, 'Density (g/cm³)'),\n",
    "        (surface, 'Surface Treatment'),\n",
    "        (material_types, 'Material Types')\n",
    "    ]\n",
    "    \n",
    "    for i, (feature_data, feature_label) in enumerate(features):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        for j in range(5):\n",
    "            plt.scatter(feature_data[material_types == j], y[material_types == j], alpha=0.5, \n",
    "                        label=material_labels[j], color=colors[j])\n",
    "        plt.title(f'{feature_label} vs. Current (Before Training)')\n",
    "        plt.xlabel(feature_label)\n",
    "        plt.ylabel('Current (mA)')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_material_properties(X, y, material_properties):\n",
    "    # Extract features\n",
    "    material_types = X[:, 2].astype(int)\n",
    "    light_intensity = X[:, 0]\n",
    "    temperature = X[:, 1]\n",
    "    humidity = X[:, 3]\n",
    "    wavelength = X[:, 4]\n",
    "    pressure = X[:, 5]\n",
    "    thickness = X[:, 6]\n",
    "    impurity = X[:, 7]\n",
    "    bias = X[:, 8]\n",
    "    electric_field = X[:, 9]\n",
    "    density = X[:, 10]\n",
    "    surface = X[:, 11]\n",
    "\n",
    "    # Define colors and labels\n",
    "    colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "    material_labels = [material_properties[i]['name'] for i in range(5)]\n",
    "\n",
    "    # Create a figure for 3D plotting\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Choose features for 3D plot (light intensity, temperature, humidity)\n",
    "    x_data = light_intensity\n",
    "    y_data = temperature\n",
    "    z_data = humidity\n",
    "\n",
    "    for j in range(5):\n",
    "        ax.scatter(x_data[material_types == j], \n",
    "                   y_data[material_types == j], \n",
    "                   z_data[material_types == j], \n",
    "                   alpha=0.5, \n",
    "                   label=material_labels[j], \n",
    "                   color=colors[j])\n",
    "\n",
    "    ax.set_title('3D Scatter Plot of Material Properties (Before Training)')\n",
    "    ax.set_xlabel('Light Intensity (Lux)')\n",
    "    ax.set_ylabel('Temperature (°C)')\n",
    "    ax.set_zlabel('Humidity (%)')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "def plot_current_in_3D(X, y, material_properties):\n",
    "    # Create a DataFrame for easier handling\n",
    "    df = pd.DataFrame(X, columns=['Light Intensity', 'Temperature', 'Material Type', 'Humidity',\n",
    "                                   'Wavelength', 'Pressure', 'Thickness', 'Impurity',\n",
    "                                   'Bias', 'Electric Field', 'Density', 'Surface Treatment'])\n",
    "    df['Current'] = y\n",
    "\n",
    "    # Convert material types to categorical for color mapping\n",
    "    df['Material Type'] = df['Material Type'].astype(int)\n",
    "\n",
    "    # Plot\n",
    "    fig = px.scatter_3d(df, \n",
    "                        x='Light Intensity', \n",
    "                        y='Temperature', \n",
    "                        z='Humidity', \n",
    "                        color='Material Type', \n",
    "                        size='Current', \n",
    "                        hover_name=df.index,\n",
    "                        title='3D Scatter Plot of Current vs Features',\n",
    "                        color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "    fig.update_traces(marker=dict(sizemode='diameter', opacity=0.7), selector=dict(mode='markers'))\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title='Light Intensity (Lux)',\n",
    "        yaxis_title='Temperature (°C)',\n",
    "        zaxis_title='Humidity (%)'\n",
    "    ))\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_vs_predicted(y_val, y_pred, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_val, y_pred, alpha=0.5)\n",
    "    plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], color='red', linestyle='--')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(y_val, y_pred, title):\n",
    "    residuals = y_val - y_pred.flatten()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_pred.flatten(), residuals)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
